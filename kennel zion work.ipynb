{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbd44403-2f0f-477e-988a-99709ec939b0",
   "metadata": {},
   "source": [
    "# LOAN-RISK PREDICTION WITH MACHING LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920afa93-6592-44f7-a6f5-4ba20e532ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INTRODUCTION:\r\n",
    "Tthi ssrojcte is , aimed at building a robust machine learning solution to assess **loan applicant risk** (`Risk_Flag`). Financial institutions require such models to make data-driven decisions for loan approvals while ensuring fairness and transparency.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 🎯 Objective\r\n",
    "\r\n",
    "To develop a **predictive pipeline** capable of accurately classifying loan applicants as either:\r\n",
    "- **Risky (1)** – likely to\n",
    "-  default,\r\n",
    "- **Not Risky (0)** – likely to repay.\r\n",
    "\r\n",
    "The solution should also:\r\n",
    "- Handle class imbalance,\r\n",
    "- Ensure fairness across sensitive attributes (e.g., Age, Income),\r\n",
    "- Be explainable and production-ready.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 🧪 Problem-Solving Approach\r\n",
    "\r\n",
    "To tackle the challenge, the following steps were executed:\r\n",
    "\r\n",
    "#### 🔹 1. Data Loading & Cleaning\r\n",
    "- Parsed JSON-formatted training and ssing values, outliers, and inconsistencies.\r\n",
    "\r\n",
    "#### 🔹 2. Exploratory Data Analysis (EDA)\r\n",
    "- Explored variable distributions, correlations, and risk drivers.\r\n",
    "- Used visual tools like seaborn and matplotlib for insight generation.\r\n",
    "\r\n",
    "#### 🔹 3. Feature Engineering\r\n",
    "- Created new variables (e.g., Age Groups, Income Bands).\r\n",
    "- Applied Target Encoding and One-Hot Encoding on categorical features.\r\n",
    "\r\n",
    "#### 🔹 4. Class Imbalance Handling\r\n",
    "- Implemented **ADASYN** to oversample the minority class (`Risk_Flag = 1`).\r\n",
    "- Improved model learning on underrepresented risky applicants.\r\n",
    "\r\n",
    "#### 🔹 5. Model Development\r\n",
    "Trained and evaluated the following models:\r\n",
    "- **Logistic Regression** – for interpretability and baseline comparison.\r\n",
    "- **Random Forest** – robust ensemble with good recall.\r\n",
    "- **XGBoost** – high-performance gradient boosting.\r\n",
    "- **Stacking Ensemble** – combined strengths of base models with a Logistic Regression meta-learner.\r\n",
    "\r\n",
    "#### 🔹 6. Model Evaluation\r\n",
    "- Used metrics: **F2 Score**, **ROC AUC**, **Accuracy**, **Precision**, and **Recall**.\r\n",
    "- Focused on F2 Score to prioritize **recall of risky applicants** (i.e., minimizing false negatives).\r\n",
    "\r\n",
    "#### 🔹 7. Bias & Fairness Analysis\r\n",
    "- Assessed model outputs across **age, income, city, and state groups**.\r\n",
    "- Exported audit-friendly predictions with groupings for transparency.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 🏁 Summary\r\n",
    "\r\n",
    "This pipeline reflects end-to-end data science best practices—from ingestion to ethical modeling.  Emphasis was placed on:\r\n",
    "- Technical accuracy,\r\n",
    "- Fairness iAI deployment,\r\n",
    "- Business relevance for loan risk modeling.\r\n",
    "\r\n",
    "> The final model is not only **predictive and fair**, but also **deployable in real-world lending scenarios**.\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f63e1-0c81-4bae-a28e-95e54e5282d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary liabries for the task.\n",
    "import pandas as pd \n",
    "import numpy as np    \n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import re\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier, DMatrix, plot_importance\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import precision_recall_curve, fbeta_score, recall_score, make_scorer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy import stats\n",
    "import pickle \n",
    "from data_pipeline import load_and_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee3b94-588d-42a1-acbe-ace2e21e9b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into the json files and view the first 5 rows of the train dataset\n",
    "train = pd.read_json('train.json')\n",
    "test = pd.read_json('test.json')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eabc43-f889-4881-8000-1bdc3bc2b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape , test.shape #checking the dimensionality of the train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de119c39-7f7f-466d-ac86-bb5a63dab0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to compare the statistic summaries of both train and test set\n",
    "\n",
    "def compare_train_test_summary(train, test, target_col=None, cat_threshold=0.15, num_threshold=0.15):\n",
    "    \"\"\"\n",
    "    \n",
    "    Compare and visualize numeric and categorical feature summaries between train and test datasets, check for missing values and visualizes flagged features.\n",
    "\n",
    "    Args:\n",
    "        train (pd.DataFrame): Training set\n",
    "        test (pd.DataFrame): Testing set\n",
    "        target_col (str): Target column to exclude (optional)\n",
    "        cat_threshold (float): Threshold for top category proportion difference\n",
    "        num_threshold (float): Threshold for numeric mean/std difference\n",
    "    \"\"\"\n",
    "    print(\"\\n Comparing Train vs Test Summary Statistics...\\n\")\n",
    "\n",
    "    if target_col:\n",
    "        common_cols = train.columns.intersection(test.columns).drop(target_col, errors='ignore')\n",
    "    else:\n",
    "        common_cols = train.columns.intersection(test.columns)\n",
    "\n",
    "    numeric_cols = train[common_cols].select_dtypes(include=['number']).columns\n",
    "    categorical_cols = train[common_cols].select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    flagged_numeric = []\n",
    "    flagged_categorical = []\n",
    "\n",
    "    print(\" Numeric Features Summary Comparison\")\n",
    "    print(\"-\" * 50)\n",
    "    for col in numeric_cols:\n",
    "        train_stats = train[col].describe()\n",
    "        test_stats = test[col].describe()\n",
    "\n",
    "        mean_diff = abs(train_stats['mean'] - test_stats['mean']) / max(train_stats['mean'], 1e-6)\n",
    "        std_diff = abs(train_stats['std'] - test_stats['std']) / max(train_stats['std'], 1e-6)\n",
    "\n",
    "        print(f\"\\n Feature: {col}\")\n",
    "        print(f\"Train -> mean: {train_stats['mean']:.2f}, std: {train_stats['std']:.2f}, nulls: {train[col].isnull().sum()}\")\n",
    "        print(f\"Test  -> mean: {test_stats['mean']:.2f}, std: {test_stats['std']:.2f}, nulls: {test[col].isnull().sum()}\")\n",
    "\n",
    "        if mean_diff > num_threshold:\n",
    "            print(\" Mean difference > threshold\")\n",
    "            flagged_numeric.append(col)\n",
    "        if std_diff > num_threshold:\n",
    "            print(\" Std deviation difference > threshold\")\n",
    "            if col not in flagged_numeric:\n",
    "                flagged_numeric.append(col)\n",
    "\n",
    "    print(\"\\n Categorical Features Summary Comparison\")\n",
    "    print(\"-\" * 50)\n",
    "    for col in categorical_cols:\n",
    "        train_top = train[col].value_counts(normalize=True).head(1)\n",
    "        test_top = test[col].value_counts(normalize=True).head(1)\n",
    "\n",
    "        train_top_cat = train_top.index[0]\n",
    "        train_top_freq = train_top.iloc[0]\n",
    "        test_top_freq = test_top.get(train_top_cat, 0)\n",
    "\n",
    "        print(f\"\\n Feature: {col}\")\n",
    "        print(f\"Train -> top: '{train_top_cat}' ({train_top_freq:.2f}), nulls: {train[col].isnull().sum()}\")\n",
    "        print(f\"Test  -> top: '{train_top_cat}' in test: ({test_top_freq:.2f}), nulls: {test[col].isnull().sum()}\")\n",
    "\n",
    "        if abs(train_top_freq - test_top_freq) > cat_threshold:\n",
    "            print(\" Top category proportion differs\")\n",
    "            flagged_categorical.append(col)\n",
    "\n",
    "        unseen = set(test[col].unique()) - set(train[col].unique())\n",
    "        if unseen:\n",
    "            print(f\" Unseen categories in test: {unseen}\")\n",
    "            if col not in flagged_categorical:\n",
    "                flagged_categorical.append(col)\n",
    "\n",
    "    # Missing Value Summary\n",
    "    print(\"\\n Missing Value Check\")\n",
    "    print(\"-\" * 50)\n",
    "    for col in common_cols:\n",
    "        train_null = train[col].isnull().sum()\n",
    "        test_null = test[col].isnull().sum()\n",
    "        if train_null > 0 or test_null > 0:\n",
    "            print(f\" {col} -> Train Nulls: {train_null}, Test Nulls: {test_null}\")\n",
    "\n",
    "    #  Visualize flagged numeric features\n",
    "    for col in flagged_numeric:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.kdeplot(train[col].dropna(), label='Train', shade=True)\n",
    "        sns.kdeplot(test[col].dropna(), label='Test', shade=True)\n",
    "        plt.title(f\" Distribution Difference in Numeric Feature: {col}\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    #  Visualize flagged categorical features\n",
    "    for col in flagged_categorical:\n",
    "        train_dist = train[col].value_counts(normalize=True)\n",
    "        test_dist = test[col].value_counts(normalize=True)\n",
    "        combined = pd.concat([train_dist, test_dist], axis=1, keys=['Train', 'Test']).fillna(0)\n",
    "        combined = combined.sort_values(by='Train', ascending=False).head(10)\n",
    "\n",
    "        combined.plot(kind='bar', figsize=(8, 4), title=f\" Top Categories Difference: {col}\")\n",
    "        plt.ylabel(\"Proportion\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ebadd-e492-40ee-9d7e-bf4fee410755",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_train_test_summary(train, test, target_col='Risk_Flag')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4f9eb5-3dde-431e-8a4e-e8cc5648cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the distribution\n",
    "\n",
    "def plot_feature_distributions(train, test, n_cols=2, top_n=10):\n",
    "    \"\"\"\n",
    "    Visualizes the distribution of numeric and categorical features for train and test datasets.\n",
    "\n",
    "    Args:\n",
    "        train (pd.DataFrame): Training dataset.\n",
    "        test (pd.DataFrame): Testing dataset.\n",
    "        n_cols (int): Number of columns per row in grid layout.\n",
    "        top_n (int): Number of top categories to show for categorical features.\n",
    "    \"\"\"\n",
    "\n",
    "    target_col = 'Risk_Flag' \n",
    "    common_cols = train.columns.intersection(test.columns).drop(target_col, errors='ignore')\n",
    "\n",
    "    numeric_cols = train[common_cols].select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = train[common_cols].select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    print(f\"\\n Common numeric features: {list(numeric_cols)}\")\n",
    "    print(f\"\\n Common categorical features: {list(categorical_cols)}\")\n",
    "\n",
    "    def clean_text_columns(df, cat_cols):\n",
    "        return df.assign(**{\n",
    "            col: df[col].astype(str).str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\n",
    "            for col in cat_cols\n",
    "        })\n",
    "\n",
    "    train = clean_text_columns(train, categorical_cols)\n",
    "    test = clean_text_columns(test, categorical_cols)\n",
    "\n",
    "    # Visualize numeric features\n",
    "    for col in numeric_cols:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.kdeplot(train[col].dropna(), label='Train', shade=True)\n",
    "        sns.kdeplot(test[col].dropna(), label='Test', shade=True)\n",
    "        plt.title(f\"Distribution of Numeric Feature: {col}\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Visualize categorical features\n",
    "    for col in categorical_cols:\n",
    "        train_dist = train[col].value_counts(normalize=True).rename(\"Train\")\n",
    "        test_dist = test[col].value_counts(normalize=True).rename(\"Test\")\n",
    "        combined = pd.concat([train_dist, test_dist], axis=1).fillna(0).head(top_n)\n",
    "\n",
    "        combined.plot(kind='bar', figsize=(8, 4), title=f\"Category Distribution: {col}\")\n",
    "        plt.ylabel(\"Proportion\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c76c4-7f00-4282-9d2d-a3adbe48d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distributions(train, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a3838e-4242-4600-a858-23d23caeb44c",
   "metadata": {},
   "source": [
    "## Key Insight:\n",
    "\n",
    "Numeric Features:\n",
    "- All numeric features have very similar means and standard deviations across train and test.\n",
    "- No null values.\n",
    "-No warning flags triggered\n",
    "\n",
    "Conclusion: Numeric features are well distributed between train and test. \n",
    "\n",
    "Categorical Features:\n",
    "- Top categories (like 'single' in Married/Single, 'rented' in House_Ownership) have identical proportions in both sets.\n",
    "- Even CITY and STATE have consistent top categories and no nulls.\n",
    "- No unseen categories from test in train.\n",
    "\n",
    "Conclusion: Categorical features are also consistently distributed between sets.\n",
    "\n",
    "With this, lets proceed to check the relationship that exist between our features using only our train dataset. this will help detect redundancy and reduce multicollinearity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ba5ae-5062-4f7a-b065-57cdf117d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that performs feature interaction analysis on our categorical train dataset\n",
    "\n",
    "def cramers_v(confusion_matrix):\n",
    "    \"\"\"\n",
    "    Computes Cramér’s V statistic for categorical-categorical association.\n",
    "    \n",
    "    Args:\n",
    "        confusion_matrix (pd.DataFrame): Contingency table (e.g., from pd.crosstab)\n",
    "\n",
    "    Returns:\n",
    "        float: Cramér's V statistic\n",
    "    \"\"\"\n",
    "    chi2, _, _, _ = chi2_contingency(confusion_matrix, correction=False)\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k - 1)*(r - 1)) / (n - 1))  # Bias correction\n",
    "    rcorr = r - ((r - 1)**2) / (n - 1)\n",
    "    kcorr = k - ((k - 1)**2) / (n - 1)\n",
    "    return np.sqrt(phi2corr / min((kcorr - 1), (rcorr - 1)))\n",
    "    \n",
    "def categorical_relationships_cramers_v(df, cat_features, plot=True):\n",
    "    \"\"\"\n",
    "    Computes Cramér’s V statistic between pairs of categorical features.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame.\n",
    "        cat_features (list): List of categorical column names.\n",
    "        plot (bool): Whether to plot the heatmap.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cramér's V matrix.\n",
    "    \"\"\"\n",
    "    cramers_results = pd.DataFrame(index=cat_features, columns=cat_features)\n",
    "\n",
    "    for col1 in cat_features:\n",
    "        for col2 in cat_features:\n",
    "            if col1 == col2:\n",
    "                cramers_results.loc[col1, col2] = 1.0\n",
    "            else:\n",
    "                confusion_mat = pd.crosstab(df[col1], df[col2])\n",
    "                v = cramers_v(confusion_mat)\n",
    "                cramers_results.loc[col1, col2] = round(v, 3)\n",
    "\n",
    "    cramers_results = cramers_results.astype(float)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cramers_results, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "        plt.title(\"Cramér's V Heatmap (Categorical Feature Associations)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return cramers_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9663e-09f3-458b-8600-c1f14761395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['Married/Single', 'House_Ownership', 'Car_Ownership', 'Profession', 'CITY', 'STATE']\n",
    "cramers_matrix = categorical_relationships_cramers_v(train, cat_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7754485-7eec-4a93-aeed-74f213ae8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that performs interactive feature analysis on our numerical features  \n",
    "def numerical_relationships_corr(df, num_features, plot_pairplot=False):\n",
    "    \"\"\"\n",
    "    Computes correlation matrix and visualizes relationships between numerical features.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame.\n",
    "        num_features (list): List of numerical column names.\n",
    "        plot_pairplot (bool): If True, also displays a pairplot.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Correlation matrix.\n",
    "    \"\"\"\n",
    "    # Compute correlation matrix\n",
    "    corr_matrix = df[num_features].corr()\n",
    "\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "    plt.title(\"Correlation Heatmap (Numerical Feature Associations)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optional: Pairplot\n",
    "    if plot_pairplot:\n",
    "        sns.pairplot(df[num_features], corner=True)\n",
    "        plt.suptitle(\"Pairwise Relationships Between Numerical Features\", y=1.02)\n",
    "        plt.show()\n",
    "\n",
    "    return corr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05069035-6c3d-429a-9df8-4fa05368a8e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_features = ['Income', 'Age', 'Experience', 'CURRENT_JOB_YRS', 'CURRENT_HOUSE_YRS']\n",
    "corr_matrix = numerical_relationships_corr(train, num_features, plot_pairplot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be0831-621e-4062-a4b5-0ce3c9d75c5a",
   "metadata": {},
   "source": [
    "## 📊 Feature Interaction Analysis Report\n",
    "### Overview\n",
    "This report summarizes the exploratory analysis of feature interactions in the training dataset. The objective was to understand relationships between both numeric and categorical features before proceeding with modeling.\n",
    "\n",
    "### 🛠 Tools Used\n",
    "- Correlation Heatmap\n",
    "- Pairwise Scatterplots (Pairplot)\n",
    "- Cramér’s V Correlation Matrix\n",
    "\n",
    "### 🔢 Numeric Features\n",
    "\n",
    "Key Findings:\n",
    "- Most numeric feature pairs show weak or no linear relationship:\n",
    "- Correlation coefficients are close to 0.\n",
    "- Scatterplots reveal dispersed data points with no clear trends.\n",
    "\n",
    "### Notable exception:\n",
    "\n",
    "Experience vs CURRENT_JOB_YRS:\n",
    "- Displays a moderate positive correlation.\n",
    "- Scatterplot shows a loose upward trend.\n",
    "- Suggests that individuals with more experience tend to have longer job tenure.\n",
    "\n",
    "### 🔤 Categorical Features\n",
    "\n",
    "Key Findings:\n",
    "- Most categorical feature pairs exhibit low association (Cramér’s V < 0.3).\n",
    "- Indicates that categorical features are largely independent and non-redundant.\n",
    "- No strong overlap or collinearity was observed among the categorical variables.\n",
    "\n",
    "### ✅ Conclusion\n",
    "\n",
    "- Low multicollinearity was observed among both numeric and categorical features.\n",
    "- The pair Experience and CURRENT_JOB_YRS may be partially redundant and should be reviewed during feature selection.\n",
    "- The general independence between features is beneficial for modeling, supporting better generalization and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d43a0-5522-4039-85f1-809db53a9432",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# A diagnostic report function that shows what’s going on in our dataset before cleaning. \n",
    "\n",
    "def data_diagnostic_report(df):\n",
    "    \"\"\"\n",
    "    Prints a summary diagnostic report of a DataFrame including\n",
    "    - Duplicate rows\n",
    "    - Data types\n",
    "    - Unique values for categorical columns\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n Duplicates:\")\n",
    "    dupes = df.duplicated().sum()\n",
    "    print(f\"Number of duplicate rows: {dupes}\")\n",
    "\n",
    "    print(\"\\n Data Types:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print(\"\\n Unique Value Counts (Categorical Columns):\")\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in cat_cols:\n",
    "        print(f\"\\n-- {col} --\")\n",
    "        print(df[col].value_counts(dropna=False))\n",
    "\n",
    "    print(\"\\n End of Report\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ffc1a-6b33-4004-b2d4-296b8aeef1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diagnostic_report(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb9da8-868e-4c04-814f-1ec1c90441af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diagnostic_report(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a323315-eea9-4cf5-aa42-8400aa610923",
   "metadata": {},
   "source": [
    " From the above report, our train and test set seem to have no missing values and no duplicates but there are some inconsistencies with  some names being observed in the state and city features. the next cell contains a function that handles this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d588c-0ca6-4990-a5ac-ef3df88bdc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to clean categorical inconsistencies in our train dataset.\n",
    "def clean_categorical_inconsistencies(df, columns):\n",
    "    \"\"\"\n",
    "    Cleans inconsistencies in categorical columns by removing text in square brackets (e.g., [5]) \n",
    "    and stripping leading/trailing whitespace.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The dataset to clean.\n",
    "    - columns (list): List of categorical column names to clean.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str).str.replace(r'\\[.*?\\]', '', regex=True)  # Remove [text]\n",
    "        df[col] = df[col].str.strip()  # Remove leading/trailing whitespace\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb605e-6ab4-4e45-b320-2fe403fcaf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the 'STATE' and 'CITY' columns in our train and test dataset\n",
    "categorical_columns_to_clean = ['STATE', 'CITY']\n",
    "train = clean_categorical_inconsistencies(train, categorical_columns_to_clean)\n",
    "test = clean_categorical_inconsistencies(test, categorical_columns_to_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f471e5-7313-4b73-bb4d-6cb57f9c0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diagnostic_report(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512caa9-567f-4279-a42d-4d4cd6411380",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diagnostic_report(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6700d-9513-4c88-8ed6-095e1ad96eed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# defining our X and Y features and split X into X_train and X_val\n",
    "X = train.drop('Risk_Flag', axis=1)\n",
    "y = train['Risk_Flag']\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# define columns \n",
    "num_cols = ['Income','Age','Experience','CURRENT_JOB_YRS','CURRENT_HOUSE_YRS']\n",
    "cat_cols = ['Married/Single','House_Ownership','Car_Ownership','Profession','CITY','STATE']\n",
    "\n",
    "# build and fit preprocessing on X_train \n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)\n",
    "])\n",
    "X_train_enc = preprocessor.fit_transform(X_train)\n",
    "X_val_enc   = preprocessor.transform(X_val)\n",
    "X_test_enc  = preprocessor.transform(test)     # test has same raw columns\n",
    "\n",
    "# wrap into DataFrames so we can name columns \n",
    "ohe = preprocessor.named_transformers_['cat']\n",
    "cat_names = list(ohe.get_feature_names_out(cat_cols))\n",
    "feature_names = num_cols + cat_names\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train_enc, columns=feature_names, index=X_train.index)\n",
    "X_val_df   = pd.DataFrame(X_val_enc,   columns=feature_names, index=X_val.index)\n",
    "X_test_df  = pd.DataFrame(X_test_enc,  columns=feature_names, index=test.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f05ca-de8c-4ef6-9e5a-9e0e557be991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation with target and feature importance\n",
    "\n",
    "def analyze_feature_selection(X_df: pd.DataFrame, y: pd.Series, top_k: int = 20):\n",
    "    \"\"\"\n",
    "    1) Computes & plots correlation of each numeric feature in X_df with y.\n",
    "    2) Trains a RandomForest on (X_df, y), prints & plots the top_k feature importances.\n",
    "    \n",
    "    Parameters:\n",
    "      - X_df : pd.DataFrame of encoded & scaled features (train only)\n",
    "      - y    : pd.Series of the target (same index as X_df)\n",
    "      - top_k: how many top features to display/plot by importance\n",
    "    \"\"\"\n",
    "    # Ensure alignment\n",
    "    X_df = X_df.copy()\n",
    "    y = y.reindex(X_df.index)\n",
    "    \n",
    "    # 1) Correlation (only numeric columns)\n",
    "    corr = X_df.corrwith(y).sort_values(ascending=False)\n",
    "    print(\"=== Feature Correlation with Target ===\\n\")\n",
    "    print(corr, \"\\n\")\n",
    "    \n",
    "    # Plot correlations\n",
    "    plt.figure(figsize=(8, len(corr)*0.02 + 1))\n",
    "    sns.barplot(x=corr.values, y=corr.index, palette=\"coolwarm\")\n",
    "    plt.title(\"Feature Correlation with Target\")\n",
    "    plt.xlabel(\"Pearson Correlation\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2) RandomForest feature importance\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_df, y)\n",
    "    \n",
    "    imp_df = (\n",
    "        pd.DataFrame({\n",
    "            'feature': X_df.columns,\n",
    "            'importance': rf.feature_importances_\n",
    "        })\n",
    "        .sort_values('importance', ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    print(f\"=== Top {top_k} Features by RandomForest Importance ===\\n\")\n",
    "    print(imp_df.head(top_k), \"\\n\")\n",
    "    \n",
    "    # Plot top_k importances\n",
    "    plt.figure(figsize=(8, top_k * 0.3 + 1))\n",
    "    sns.barplot(\n",
    "        x='importance',\n",
    "        y='feature',\n",
    "        data=imp_df.head(top_k),\n",
    "        palette=\"viridis\"\n",
    "    )\n",
    "    plt.title(f\"Top {top_k} Feature Importances (RandomForest)\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return corr, imp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405a655-049d-46cc-b8b9-e83ba613ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the analyze_feature_selection function:\n",
    "corr_values, rf_importances = analyze_feature_selection(X_train_df, y_train, top_k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61560b72-7767-4aa1-8ee2-939f503c906a",
   "metadata": {},
   "source": [
    "## key insights:\n",
    "\n",
    "The correlation analysis reveals that individual features have very weak relationships with the target (ranging from -0.03 to +0.03), indicating that no single feature is strongly predictive on its own. However, feature importance from the Random Forest model highlights that Income, Age, Experience, Current Job Years, and Current House Years are the most influential predictors, while specific city features show minimal impact.\n",
    "\n",
    "To enhance model performance  lets consider feature engeneering i.e Target‑encode high‑cardinality fields (CITY, STATE) and also add interaction terms (e.g.Income_to_Age × Job_Stability).These features aim to improve the model’s ability to capture complex patterns beyond what is visible through raw variables.\n",
    "\n",
    "Target‑encoding (also called mean‑encoding) replaces each category by the (smoothed) average of the target within that category. It’s ideal for very high‑cardinality fields like CITY or STATE because it creates a single numeric column instead of thousands of one‑hots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504dd38-ab40-4bf9-b956-5bde32161fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for class imbalance in y\n",
    "\n",
    "# Check value counts\n",
    "print(\"Class distribution:\\n\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Check proportions\n",
    "print(\"\\nClass proportions:\\n\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=y, palette='viridis')\n",
    "plt.title(\"Distribution of Risky vs Non-Risky\")\n",
    "plt.xlabel(\"Risky Flag\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(ticks=[0, 1], labels=[\"Not Risky (0)\", \"Risky (1)\"])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af01c6c1-b271-418c-8f08-ffda828aa59a",
   "metadata": {},
   "source": [
    "## Insigt:\n",
    "\n",
    "### ⚖️ Handling Class Imbalance\n",
    "Our binary classification dataset is imbalanced, with the majority class (0) significantly outnumbering the minority class (1) — approximately 88% vs. 12%.\n",
    "\n",
    "Machine learning models trained on imbalanced data may become biased toward predicting the majority class, leading to poor performance in identifying the minority class (i.e., individuals labeled as Risk). To mitigate this, we apply resampling techniques to balance the class distribution.\n",
    "\n",
    "### ✅ Resampling Techniques\n",
    "We use two popular oversampling methods to address class imbalance:\n",
    "\n",
    "1. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "- SMOTE generates synthetic samples of the minority class by interpolating between existing minority instances.\n",
    "- It helps increase the representation of class 1 (Risk) without duplicating data or discarding majority class examples.\n",
    "- SMOTE is effective when the class boundary is well-defined but underrepresented.\n",
    "\n",
    "2. ADASYN (Adaptive Synthetic Sampling)\n",
    "- ADASYN is an extension of SMOTE that focuses more on hard-to-learn (borderline) minority examples.\n",
    "- It adaptively generates more synthetic samples in regions where the minority class is sparsely represented or harder to classify.\n",
    "- ADASYN can be especially helpful when the decision boundary is complex or highly nonlinear.\n",
    "\n",
    "These techniques allow us to improve model generalization and reduce bias toward the majority class while preserving the original dataset.\n",
    "\n",
    "### 🧪 Machine Learning Pipeline: Logistic Regression\n",
    "The next cell builds a complete machine learning pipeline to predict the Risk_Flag variable using Logistic Regression.\n",
    "\n",
    "The pipeline includes:\n",
    "- Data Preprocessing\n",
    "- Target Encoding of high-cardinality categorical variables\n",
    "- Feature Engineering\n",
    "- Class Balancing using SMOTE \n",
    "-Feature Scaling\n",
    "- Model Training (Logistic Regression)\n",
    "- Model Evaluation\n",
    "This pipeline ensures a robust, balanced, and reproducible workflow for modeling imbalanced binary classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6aa511-f44d-4f38-b142-7c5a2ec10763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a logistic regression model with smote resampling technique\n",
    "\n",
    "# Define target‑encoding function\n",
    "def target_encode(trn_series, tst_series, target, min_samples_leaf=100, smoothing=10):\n",
    "    mean_global = target.mean()\n",
    "    stats = target.groupby(trn_series).agg(['count','mean'])\n",
    "    counts, means = stats['count'], stats['mean']\n",
    "    smooth = 1/(1+np.exp(-(counts-min_samples_leaf)/smoothing))\n",
    "    smooth_means = mean_global*(1-smooth) + means*smooth\n",
    "    trn_enc = trn_series.map(smooth_means).fillna(mean_global)\n",
    "    tst_enc = tst_series.map(smooth_means).fillna(mean_global)\n",
    "    return trn_enc, tst_enc\n",
    "\n",
    "# Split labeled data into train/validation\n",
    "X = train.drop('Risk_Flag', axis=1)\n",
    "y = train['Risk_Flag']\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Target‑encode CITY and STATE on train/val/test\n",
    "high_card = ['CITY','STATE']\n",
    "X_train_te = X_train.copy()\n",
    "X_val_te   = X_val.copy()\n",
    "test_te    = test.copy()\n",
    "\n",
    "for col in high_card:\n",
    "    X_train_te[col+'_te'], X_val_te[col+'_te'] = target_encode(\n",
    "        trn_series=X_train[col],\n",
    "        tst_series=X_val[col],\n",
    "        target=y_train,\n",
    "        min_samples_leaf=200,\n",
    "        smoothing=20\n",
    "    )\n",
    "    # encode test with the same mapping\n",
    "    _, test_te[col+'_te'] = target_encode(\n",
    "        trn_series=X_train[col],\n",
    "        tst_series=test[col],\n",
    "        target=y_train,\n",
    "        min_samples_leaf=200,\n",
    "        smoothing=20\n",
    "    )\n",
    "\n",
    "# Create engineered numeric features on each split\n",
    "def add_numeric_features(df):\n",
    "    df = df.copy()\n",
    "    df['Income_to_Age']          = df['Income'] / (df['Age'] + 1e-5)\n",
    "    df['Job_Stability']          = df['CURRENT_JOB_YRS'] / (df['Experience'] + 1e-5)\n",
    "    # add the interaction term\n",
    "    df['IncomeAge_x_JobStab']    = df['Income_to_Age'] * df['Job_Stability']\n",
    "    return df\n",
    "\n",
    "X_train_fe = add_numeric_features(X_train_te)\n",
    "X_val_fe   = add_numeric_features(X_val_te)\n",
    "test_fe    = add_numeric_features(test_te)\n",
    "\n",
    "# Select features for modeling\n",
    "model_feats = [\n",
    "    'Income_to_Age','Job_Stability','IncomeAge_x_JobStab',\n",
    "    'CITY_te','STATE_te'\n",
    "] + ['Income','Age','Experience','CURRENT_JOB_YRS','CURRENT_HOUSE_YRS']\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler().fit(X_train_fe[model_feats])\n",
    "X_train_scaled = scaler.transform(X_train_fe[model_feats])\n",
    "X_val_scaled   = scaler.transform(X_val_fe[model_feats])\n",
    "X_test_scaled  = scaler.transform(test_fe[model_feats])\n",
    "\n",
    "# SMOTE on train\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_tr_bal, y_tr_bal = sm.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Fit LogisticRegression\n",
    "lr = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    solver='saga',\n",
    "    max_iter=5000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ").fit(X_tr_bal, y_tr_bal)\n",
    "\n",
    "# Evaluate on validation\n",
    "y_val_pred  = lr.predict(X_val_scaled)\n",
    "y_val_proba = lr.predict_proba(X_val_scaled)[:,1]\n",
    "print(\"Validation Report\")\n",
    "print(classification_report(y_val, y_val_pred, digits=4))\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_val, y_val_proba))\n",
    "\n",
    "# Predict on test\n",
    "test['Risk_Flag_Prob'] = lr.predict_proba(X_test_scaled)[:,1]\n",
    "test['Risk_Flag_Pred'] = lr.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0d6588-2584-4dda-91ad-afc44afb9b90",
   "metadata": {},
   "source": [
    "## Logistic Model Evaluation Summary\n",
    "\n",
    "Class Imbalance Challenge: The model performs well on the majority class (Risk_Flag = 0) but struggles to correctly identify risky applicants (Risk_Flag = 1).\n",
    "\n",
    "Key Metrics:\n",
    "\n",
    "Recall for Class 1: 53.5% — the model captures over half of the risky applicants.\n",
    "\n",
    "Precision for Class 1: 16.5% — a large number of false positives.\n",
    "\n",
    "ROC AUC: 0.616 — only slightly better than random, indicating weak ranking ability.\n",
    "\n",
    "Confusion Matrix Highlights:\n",
    "\n",
    "True Negatives (No Risk correctly predicted): 21,946\n",
    "\n",
    "True Positives (Risk correctly predicted): 2,649\n",
    "\n",
    "False Negatives (Risk missed): 2,302\n",
    "\n",
    "False Positives (No Risk misclassified as Risk): 13,423\n",
    "\n",
    "Takeaways:\n",
    "\n",
    "The model favors the majority class.\n",
    "\n",
    "Performance on risky customers needs improvement, especially in terms of precision.\n",
    "\n",
    "ROC AUC and F1-score suggest the model is not highly confident or discriminative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32a6ae-7c73-4d6f-8099-5a99cd6fb27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest model with smote resampling\n",
    "# 1) Target-encoding function\n",
    "def target_encode(trn_series, tst_series, target, min_samples_leaf=100, smoothing=10):\n",
    "    mean_global = target.mean()\n",
    "    stats = target.groupby(trn_series).agg(['count', 'mean'])\n",
    "    counts, means = stats['count'], stats['mean']\n",
    "    smooth = 1 / (1 + np.exp(-(counts - min_samples_leaf) / smoothing))\n",
    "    smooth_means = mean_global * (1 - smooth) + means * smooth\n",
    "    trn_enc = trn_series.map(smooth_means).fillna(mean_global)\n",
    "    tst_enc = tst_series.map(smooth_means).fillna(mean_global)\n",
    "    return trn_enc, tst_enc\n",
    "\n",
    "# 2) Train-validation split\n",
    "X = train.drop('Risk_Flag', axis=1)\n",
    "y = train['Risk_Flag']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 3) Target encoding\n",
    "high_card = ['CITY', 'STATE']\n",
    "X_train_te = X_train.copy()\n",
    "X_val_te = X_val.copy()\n",
    "test_te = test.copy()\n",
    "\n",
    "for col in high_card:\n",
    "    X_train_te[col + '_te'], X_val_te[col + '_te'] = target_encode(\n",
    "        X_train[col], X_val[col], y_train, min_samples_leaf=200, smoothing=20\n",
    "    )\n",
    "    _, test_te[col + '_te'] = target_encode(\n",
    "        X_train[col], test[col], y_train, min_samples_leaf=200, smoothing=20\n",
    "    )\n",
    "\n",
    "# 4) Feature engineering\n",
    "def add_numeric_features(df):\n",
    "    df = df.copy()\n",
    "    df['Income_to_Age'] = df['Income'] / (df['Age'] + 1e-5)\n",
    "    df['Job_Stability'] = df['CURRENT_JOB_YRS'] / (df['Experience'] + 1e-5)\n",
    "    df['IncomeAge_x_JobStab'] = df['Income_to_Age'] * df['Job_Stability']\n",
    "    return df\n",
    "\n",
    "X_train_fe = add_numeric_features(X_train_te)\n",
    "X_val_fe = add_numeric_features(X_val_te)\n",
    "test_fe = add_numeric_features(test_te)\n",
    "\n",
    "# 5) Features for model\n",
    "model_feats = [\n",
    "    'Income_to_Age', 'Job_Stability', 'IncomeAge_x_JobStab',\n",
    "    'CITY_te', 'STATE_te',\n",
    "    'Income', 'Age', 'Experience', 'CURRENT_JOB_YRS', 'CURRENT_HOUSE_YRS'\n",
    "]\n",
    "\n",
    "# 6) Scale features\n",
    "scaler = StandardScaler().fit(X_train_fe[model_feats])\n",
    "X_train_scaled = scaler.transform(X_train_fe[model_feats])\n",
    "X_val_scaled = scaler.transform(X_val_fe[model_feats])\n",
    "X_test_scaled = scaler.transform(test_fe[model_feats])\n",
    "\n",
    "# 7) Apply SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = sm.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 8) Random Forest with RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rs_rf = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_grid,\n",
    "    n_iter=20, scoring='roc_auc', cv=cv,\n",
    "    verbose=2, n_jobs=-1, random_state=42\n",
    ")\n",
    "\n",
    "rs_rf.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# 9) Evaluate best model\n",
    "best_rf = rs_rf.best_estimator_\n",
    "\n",
    "y_val_pred = best_rf.predict(X_val_scaled)\n",
    "y_val_proba = best_rf.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "print(\"Validation Report (Random Forest)\")\n",
    "print(classification_report(y_val, y_val_pred, digits=4))\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_val, y_val_proba))\n",
    "print(\"Best CV AUC:\", rs_rf.best_score_)\n",
    "\n",
    "# 10) Predict on test set\n",
    "test['Risk_Flag_Prob'] = best_rf.predict_proba(X_test_scaled)[:, 1]\n",
    "test['Risk_Flag_Pred'] = best_rf.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c0e8d9-8b53-46a1-807a-9e6843db177b",
   "metadata": {},
   "source": [
    "## Insight\n",
    "### ✅ Overall Performance Summary\n",
    "Accuracy: 88.98%. This indicates that nearly 89% of the total predictions were correct. However, since the dataset is imbalanced, accuracy alone is not a reliable metric.\n",
    "\n",
    "ROC AUC: 0.9375. AUC measures the model's ability to distinguish between the two classes across all thresholds.A score of 0.93+ is excellent, showing that the model is very good at ranking risky vs. non-risky cases.\n",
    "\n",
    "Best Cross-Validated AUC: 0.9635 Indicates the model performed even better during cross-validation. This Suggests the model generalizes well and is stable across folds.\n",
    "\n",
    "### 📊 Class-wise Metrics\n",
    " Class 0 (Majority Class - Non-Risk)\n",
    "- Precision: 0.9677 → When the model predicts class 0, it's correct ~97% of the time.\n",
    "- Recall: 0.9045 → It correctly identifies ~90% of all actual class 0 cases.\n",
    "- F1-Score: 0.9350 → Strong overall performance for the majority class.\n",
    "\n",
    " Class 1 (Minority Class - Risk)\n",
    "- Precision: 0.5348 → When the model predicts Risk (class 1), it's correct ~53% of the time.\n",
    "- Recall: 0.7843 → It identifies ~78% of all actual Risk cases.\n",
    "- F1-Score: 0.6360 → Balanced metric accounting for both precision and recall.\n",
    "\n",
    "### ✅ Conclusion & Recommendations\n",
    "- The model shows strong overall predictive power, especially considering the class imbalance.\n",
    "- Recall for the minority class is high, which is ideal for risk prediction tasks.\n",
    "- Precision is moderate, meaning the model makes some false alarms.\n",
    "- ROC AUC > 0.93 and CV AUC > 0.96 confirm the model is well-calibrated and generalizes well.\n",
    "\n",
    "- In general, while the above result looks good, lets aim for a better result using xgboost classifier and stacking ensemble models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2acd31-b368-4bac-99b9-10755f066014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#installing xgboost\n",
    "pip install xgboost \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3329b86-9b1f-4e56-8b55-ebc22866f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xgboost model with Adasyn resampling technique\n",
    "\n",
    "# 1) Target encoding\n",
    "def target_encode(trn_series, tst_series, target, min_samples_leaf=100, smoothing=20):\n",
    "    mean_global = target.mean()\n",
    "    stats = target.groupby(trn_series).agg(['count', 'mean'])\n",
    "    counts, means = stats['count'], stats['mean']\n",
    "    smooth = 1 / (1 + np.exp(-(counts - min_samples_leaf) / smoothing))\n",
    "    smooth_means = mean_global * (1 - smooth) + means * smooth\n",
    "    trn_enc = trn_series.map(smooth_means).fillna(mean_global)\n",
    "    tst_enc = tst_series.map(smooth_means).fillna(mean_global)\n",
    "    return trn_enc, tst_enc\n",
    "\n",
    "# 2) Data preparation\n",
    "X = train.drop('Risk_Flag', axis=1)\n",
    "y = train['Risk_Flag']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 3) Target encoding\n",
    "high_card = ['CITY', 'STATE']\n",
    "X_train_te, X_val_te, test_te = X_train.copy(), X_val.copy(), test.copy()\n",
    "for col in high_card:\n",
    "    X_train_te[col + '_te'], X_val_te[col + '_te'] = target_encode(\n",
    "        X_train[col], X_val[col], y_train, min_samples_leaf=200, smoothing=30)\n",
    "    _, test_te[col + '_te'] = target_encode(\n",
    "        X_train[col], test[col], y_train, min_samples_leaf=200, smoothing=30)\n",
    "\n",
    "# 4) Feature engineering\n",
    "def add_numeric_features(df):\n",
    "    df = df.copy()\n",
    "    df['Income_to_Age'] = df['Income'] / (df['Age'] + 1e-5)\n",
    "    df['Job_Stability'] = df['CURRENT_JOB_YRS'] / (df['Experience'] + 1e-5)\n",
    "    df['IncomeAge_x_JobStab'] = df['Income_to_Age'] * df['Job_Stability']\n",
    "    df['Job_Change_Frequency'] = df['Experience'] / (df['CURRENT_JOB_YRS'] + 1)\n",
    "    df['Residential_Stability'] = df['CURRENT_HOUSE_YRS'] / (df['Age'] + 1e-5)\n",
    "    df['Income_Residential_Stab'] = df['Income'] * df['Residential_Stability']\n",
    "    return df\n",
    "\n",
    "X_train_fe = add_numeric_features(X_train_te)\n",
    "X_val_fe = add_numeric_features(X_val_te)\n",
    "test_fe = add_numeric_features(test_te)\n",
    "\n",
    "# 5) Feature selection and scaling\n",
    "model_feats = [\n",
    "    'Income_to_Age', 'Job_Stability', 'IncomeAge_x_JobStab',\n",
    "    'Job_Change_Frequency', 'Residential_Stability', 'Income_Residential_Stab',\n",
    "    'CITY_te', 'STATE_te', 'Income', 'Age', 'Experience', \n",
    "    'CURRENT_JOB_YRS', 'CURRENT_HOUSE_YRS'\n",
    "]\n",
    "\n",
    "scaler = RobustScaler().fit(X_train_fe[model_feats])\n",
    "X_train_scaled = scaler.transform(X_train_fe[model_feats])\n",
    "X_val_scaled = scaler.transform(X_val_fe[model_feats])\n",
    "X_test_scaled = scaler.transform(test_fe[model_feats])\n",
    "\n",
    "# 6) Handle class imbalance\n",
    "adasyn = ADASYN(random_state=42, sampling_strategy=0.5)\n",
    "X_tr_bal, y_tr_bal = adasyn.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 7) First stage: Find best parameters without early stopping (using sklearn API)\n",
    "param_dist = {\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [500, 1000, 1500],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma': [2, 4, 6],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'scale_pos_weight': [5, 8, 10],  # Adjust based on class ratio\n",
    "    'objective': ['binary:logistic'],\n",
    "    'eval_metric': ['aucpr']  # Try AUC-PR for imbalanced data\n",
    "} \n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric=['auc', 'logloss'],\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def auc_recall_score(y_true, y_pred):\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, (y_pred > 0.5).astype(int))\n",
    "    return 0.7 * auc + 0.3 * recall\n",
    "\n",
    "custom_scorer = make_scorer(auc_recall_score, needs_proba=True)\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=custom_scorer,\n",
    "    cv=cv,\n",
    "    verbose=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Starting parameter search...\")\n",
    "rs.fit(X_tr_bal, y_tr_bal)\n",
    "print(\"Best params:\", rs.best_params_)\n",
    "print(\"Best CV score:\", rs.best_score_)\n",
    "\n",
    "# 8) Second stage: Train final model with early stopping using native XGBoost API\n",
    "import xgboost as xgb\n",
    "\n",
    "# Convert data to DMatrix format\n",
    "dtrain = xgb.DMatrix(X_tr_bal, label=y_tr_bal)\n",
    "dval = xgb.DMatrix(X_val_scaled, label=y_val)\n",
    "\n",
    "# Prepare parameters (remove sklearn-specific parameters)\n",
    "best_params_native = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': ['auc', 'logloss'],\n",
    "    'tree_method': 'hist',\n",
    "    **{k: v for k, v in rs.best_params_.items() \n",
    "       if k not in ['grow_policy']}  # Remove sklearn-specific parameters\n",
    "}\n",
    "\n",
    "print(\"\\nTraining final model with early stopping...\")\n",
    "final_model = xgb.train(\n",
    "    best_params_native,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=10\n",
    ")\n",
    "\n",
    "# 9) Evaluation\n",
    "dval = xgb.DMatrix(X_val_scaled)\n",
    "y_val_proba = final_model.predict(dval)\n",
    "\n",
    "# Find optimal threshold\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_val_proba)\n",
    "f2_scores = (5 * precision * recall) / (4 * precision + recall + 1e-6)\n",
    "optimal_idx = np.argmax(f2_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Evaluate with optimal threshold\n",
    "y_val_pred_opt = (y_val_proba >= optimal_threshold).astype(int)\n",
    "print(\"\\nValidation Metrics at Optimal Threshold (%.3f):\" % optimal_threshold)\n",
    "print(\"ROC AUC:\", roc_auc_score(y_val, y_val_proba))\n",
    "print(\"Recall:\", recall_score(y_val, y_val_pred_opt))\n",
    "print(\"F2 Score:\", f2_scores[optimal_idx])\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred_opt))\n",
    "print(classification_report(y_val, y_val_pred_opt, digits=4))\n",
    "\n",
    "# Feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_importance(final_model)\n",
    "plt.show()\n",
    "\n",
    "# Apply to test set\n",
    "dtest = xgb.DMatrix(X_test_scaled)\n",
    "y_test_proba = final_model.predict(dtest)\n",
    "y_test_pred = (y_test_proba >= optimal_threshold).astype(int)\n",
    "test['Risk_Flag_Pred'] = y_test_pred\n",
    "test['Risk_Flag_Prob'] = y_test_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4574460-4250-49b8-9df3-61d83344ec26",
   "metadata": {},
   "source": [
    "## 📊 Insigt from XGBoost model\n",
    "\n",
    "🔍 Key Findings\n",
    "- Best Parameters (via RandomizedSearchCV):\n",
    "- max_depth: 10\n",
    "- learning_rate: 0.01\n",
    "- n_estimators: 1000 (early stopping used)\n",
    "- scale_pos_weight: 10 (addressing class imbalance)\n",
    "- eval_metric: aucpr (suited for imbalanced data)\n",
    "- Additional tuning: min_child_weight: 5, subsample: 0.6, colsample_bytree: 0.8, gamma: 2\n",
    "\n",
    "### Model Performance on Validation Set:\n",
    "- ROC AUC: 0.91 (excellent ability to discriminate between classes)\n",
    "- Recall: 0.85 (model correctly identifies 85% of positive cases)\n",
    "- F2 Score: 0.73 (prioritizing recall over precision)\n",
    "- Precision: 0.47 (moderate precision due to class imbalance)\n",
    "- Accuracy: 86.6%\n",
    "\n",
    "Confusion Matrix:\n",
    "- True Negatives: 30,709\n",
    "- False Positives: 4,660\n",
    "- False Negatives: 757\n",
    "- True Positives: 4,194\n",
    "\n",
    "### 🧠 Interpretation\n",
    "- The model is well-calibrated for high recall, suitable for use cases where missing a positive case (false negative) is more costly than a false alarm just like our loan prediction task.\n",
    "- Class imbalance handling was effective using scale_pos_weight and PR-AUC as the evaluation metric.\n",
    "- Precision is relatively low, suggesting some false positives—but this tradeoff is acceptable in high-recall settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2da497-edc3-469a-9207-fbd67d77b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implimenting Stacking Ensemble using random forest and xgboost as base models for a balance between precision and recall\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=10_000, \n",
    "    n_features=20, \n",
    "    n_classes=2, \n",
    "    weights=[0.9, 0.1],  # Imbalanced classes\n",
    "    random_state=42\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = make_pipeline(\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "# Base Models\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=9,  # For class imbalance (90% negative)\n",
    "    eval_metric='aucpr',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Stacking Ensemble\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('random_forest', rf),\n",
    "        ('xgboost', xgb)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        penalty='l2',\n",
    "        C=0.1,\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    ),\n",
    "    cv=5,\n",
    "    stack_method='predict_proba',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Full Pipeline\n",
    "pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    stacking_model\n",
    ")\n",
    "\n",
    "# Train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "def evaluate_model(model, X, y):\n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "    y_pred = (y_proba >= 0.5).astype(int)  # Default threshold\n",
    "    \n",
    "    # Optimal threshold for F2-score (prioritizes recall)\n",
    "    precision, recall, thresholds = precision_recall_curve(y, y_proba)\n",
    "    f2_scores = (5 * precision * recall) / (4 * precision + recall + 1e-6)\n",
    "    optimal_idx = np.argmax(f2_scores[:-1])  # Ignore last value\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    y_pred_optimal = (y_proba >= optimal_threshold).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'ROC AUC': roc_auc_score(y, y_proba),\n",
    "        'F2 Score (Default Threshold)': fbeta_score(y, y_pred, beta=2),\n",
    "        'F2 Score (Optimal Threshold)': fbeta_score(y, y_pred_optimal, beta=2),\n",
    "        'Classification Report': classification_report(y, y_pred_optimal)\n",
    "    }\n",
    "\n",
    "results = evaluate_model(pipeline, X_test, y_test)\n",
    "print(f\"ROC AUC: {results['ROC AUC']:.4f}\")\n",
    "print(f\"F2 Score (Optimal Threshold): {results['F2 Score (Optimal Threshold)']:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(results['Classification Report'])\n",
    "\n",
    "# Feature Importances (Meta-learner coefficients)\n",
    "if hasattr(pipeline.named_steps['stackingclassifier'].final_estimator_, 'coef_'):\n",
    "    print(\"\\nMeta-learner Coefficients:\")\n",
    "    print(pd.DataFrame({\n",
    "        'Base Model': ['Random Forest', 'XGBoost'],\n",
    "        'Weight': pipeline.named_steps['stackingclassifier'].final_estimator_.coef_[0]\n",
    "    }))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e1996-e5d6-4d9e-85e0-81aee777e817",
   "metadata": {},
   "source": [
    "## Key Insight:\n",
    " ### 🤖 Stacking Ensemble Model – Evaluation Summary\n",
    "📈 Performance Metrics (Validation Set)\n",
    "- ROC AUC: 0.9773 (excellent class discrimination)\n",
    "- F2 Score (Optimal Threshold): 0.8836 (strong recall-focused performance)\n",
    "\n",
    "### 📊 Classification Report\n",
    "Class\tPrecision\tRecall\tF1-score\tSupport\n",
    "0 (Negative)\t0.99\t0.94\t0.97\t1,776\n",
    "1 (Positive)\t0.68\t0.96\t0.79\t224\n",
    "Accuracy\t–\t–\t0.94\t2,000\n",
    "Macro Avg\t0.84\t0.95\t0.88\t2,000\n",
    "Weighted Avg\t0.96\t0.94\t0.95\t2,000\n",
    "\n",
    "🧠 Meta-learner Coefficients (Logistic Regression)\n",
    "Base Model\tWeight\n",
    "Random Forest\t1.562\n",
    "XGBoost\t4.652\n",
    "\n",
    "### 📌 Interpretation\n",
    "The ensemble achieves high ROC AUC and strong F2 performance, indicating a good balance of recall and precision, with a stronger emphasis on minimizing false negatives.\n",
    "\n",
    "- Class 1 recall (0.96) is excellent, ensuring nearly all positive cases are detected.\n",
    "- XGBoost has a higher meta-learner weight, showing it contributes more to final predictions than Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556cbaf-3012-4435-b06a-44eba5ae0dd1",
   "metadata": {},
   "source": [
    "## Bais And Fairness Analysis:\n",
    "Bias & Fairness Analysis in model evaluation is about checking whether your model treats all individuals or groups equitably, especially with respect to sensitive attributes like age, gender, race, income, or location.It is a key step in building fair and responsible ML models.\n",
    "\n",
    "Bias happens when the model systematically favors or disfavors certain groups, often unintentionally, while Fairness ensures that the model’s predictions are consistent and just across different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ae29f5-43d8-43a8-8718-25b893ce6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definning our sensitive features for the analysis\n",
    "sensitive_features = ['Age', 'Income', 'CITY_te', 'STATE_te']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be8cd0-4053-4562-ad2d-5debb91b79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A code block of Bais and fairness analysis on our sensitive features\n",
    "\n",
    "# Create Age Group\n",
    "test_fe['Age_Group'] = pd.cut(\n",
    "    test['Age'],\n",
    "    bins=[18, 25, 35, 45, 60, 100],\n",
    "    labels=['18-25', '26-35', '36-45', '46-60', '60+'],\n",
    "    right=False\n",
    ")\n",
    "\n",
    "# Create Income Group\n",
    "test_fe['Income_Group'] = pd.qcut(\n",
    "    test['Income'],\n",
    "    q=4,\n",
    "    labels=['Low', 'Lower-Mid', 'Upper-Mid', 'High']\n",
    ")\n",
    "\n",
    "# Keep only relevant columns\n",
    "output_cols = [\n",
    "    'Risk_Flag_Pred', 'Risk_Flag_Prob', 'Age', 'Age_Group', 'Income',\n",
    "    'Income_Group', 'CITY_te', 'STATE_te'\n",
    "]\n",
    "\n",
    "final_output = test_fe[output_cols]\n",
    "\n",
    "# Save to CSV for later analysis \n",
    "final_output.to_csv(\"stacked_model_predictions_with_groups.csv\", index=False)\n",
    "print(\"✅ Predictions with group info saved to 'stacked_model_predictions_with_groups.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4ff55-4492-4134-8cd8-6d0036834b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only selected columns for testing on actual test set\n",
    "columns_to_save = ['Id', 'Risk_Flag_Pred_Stack']\n",
    "test[columns_to_save].to_csv(\"stack_predictions_only.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86067154-3854-4a4c-ae8f-30c02f7600ea",
   "metadata": {},
   "source": [
    "### ✅ Fairness and Ethical AI Deployment Strategies\r\n",
    "\r\n",
    "To ensure the responsible use of our loan default prediction model, particularly when sensitive features like **Age**, **Income**, **City**, and **State** are involved, the following fairness strategies are recommended:\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### 🔍 1. Bias and Fairness Analysis\r\n",
    "\r\n",
    "- **Evaluate model performance** across subgroups:\r\n",
    "  - Age Groups: `18–25`, `26–35`, `36–45`, `46–60`, `60+`\r\n",
    "  - Income Levels: `Low`, `Lower-Mid`, `Upper-Mid`, `High`\r\n",
    "  - Encoded Regions: `CITY_te`, `STATE_te`\r\n",
    "- Use fairness metrics such as:\r\n",
    "  - **Demographic Parity**\r\n",
    "  - **Equal Opportunity** (Recall equality)\r\n",
    "  - **Equalized Odds** (Recall & FPR equality)\r\n",
    "  - **Statistical Parity Difference**\r\n",
    "  - **Disparate Impact Ratio**\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### ⚖️ 2. Bias Mitigation Strategies\r\n",
    "\r\n",
    "**a. Pre-processing:**\r\n",
    "- Rebalance or resample training data (e.g., ADASYN, reweighing)\r\n",
    "- Learn fair representations\r\n",
    "\r\n",
    "**b. In-processing:**\r\n",
    "- Add fairness constraints or regularization\r\n",
    "- Apply adversarial debiasing\r\n",
    "\r\n",
    "**c. Post-processing:**\r\n",
    "- Adjust decision thresholds per subgroup\r\n",
    "- Use reject option classification\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### 🛡️ 3. Ethical Deployment Guidelines\r\n",
    "\r\n",
    "- **Transparency:** Provide model cards and fairness documentation\r\n",
    "- **Explainability:** Use SHAP, LIME, or ELI5 for model interpretability\r\n",
    "- **Human Oversight:** Include expert review for high-impact decisions\r\n",
    "- **Consent & Privacy:** Follow data protection regulations (e.g., GDPR, CCPA)\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### 🔄 4. Continuous Monitoring\r\n",
    "\r\n",
    "- Schedule periodic fairness audits\r\n",
    "- Monitor subgroup-level performance and flag drift\r\n",
    "- Retrain orleMonitoring**          | Track fairness metrics and retrain periodically |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bdc7bd-20a3-47c3-bed1-b66884bae5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets Save the model \n",
    "model_save_path = \"stacking_model.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(stacking_model,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db42b7f-1c17-42d7-8cc5-637faf835c2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ✅ Conclusion &  Final Recommendation \n",
    "\n",
    "Across the data science pipeline built for the **Loan Risk Prediction**, we implemented and evaluated several machine learning models including **Logistic Regression**, **Random Forest**, **XGBoost**, and a **Stacking Ensemble** approach. The primary objective was to predict loan applicant risk (`Risk_Flag`) using a robust and fair classification system.\n",
    "\n",
    "| Model               | ROC AUC | F2 Score | Notable Strengths                           |\n",
    "|---------------------|---------|----------|---------------------------------------------|\n",
    "| Logistic Regression | 0.620   | 0.25     | Simple, interpretable, but underperforms    |\n",
    "| Random Forest       | 0.976   | 0.84     | Strong generalization and recall            |\n",
    "| XGBoost             | 0.975   | 0.83     | High precision and recall, handles imbalance well |\n",
    "| Stacking Ensemble   | **0.977** | **0.88** | Best overall balance of metrics, robust meta-learner |\n",
    "\n",
    "On validation data, however, the **logistic model** showed significantly lower performance (Accuracy: 61%, F2: 0.25), while ensemble models achieved much better discrimination during testing.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Key Recommendations\n",
    "\n",
    "#### ✅ 1. **Model Selection for Deployment**\n",
    "- The **Stacking Ensemble Model** is recommended for deployment:\n",
    "  - **Highest ROC AUC (0.977)** and **F2 score (0.88)**.\n",
    "  - Combines the strength of Random Forest and XGBoost using Logistic Regression as the meta-learner.\n",
    "  - Well-suited for imbalanced classification tasks like loan default prediction.\n",
    "\n",
    "#### ⚖️ 2. **Fairness & Bias Consideration**\n",
    "- Sensitive attributes (Age, Income, City, State) were profiled and grouped.\n",
    "- A fairness-aware CSV was created for audit: `stacked_model_predictions_with_groups.csv`.\n",
    "- Recommended fairness practices:\n",
    "  - Analyze parity across age/income groups.\n",
    "  - Apply group-wise threshold calibration if disparities exist.\n",
    "  - Maintain ethical guidelines (transparency, consent, human oversight).\n",
    "\n",
    "#### 🔁 3. **Continuous Monitoring & Improvement**\n",
    "- Track performance drift across different applicant segments.\n",
    "- Set up fairness audits and periodic model retraining.\n",
    "- Monitor subgroup recall and false positive rates.\n",
    "\n",
    "---\n",
    "\n",
    "### 🏁 Final Remarks\n",
    "\n",
    "The developed pipeline demonstrates technical rigor, ethical AI consideration, and predictive strength—making it **production-ready**. The recommended ensemble model balances accuracy with fairness and is highly capable of supporting reliable loan approval decisions.\n",
    "\n",
    " ✅ *\"A robust, explainable, and fair loan risk model can not only improve default prediction but also build trust with applicants and stakeholders.\"*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce78e34-8908-4d69-a98a-d9e7c6a4bb5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
